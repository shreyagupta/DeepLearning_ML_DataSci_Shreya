{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''Trains a simple convnet on the MNIST dataset.\n",
    "Gets to 99.25% test accuracy after 12 epochs\n",
    "(there is still a lot of margin for parameter tuning).\n",
    "16 seconds per epoch on a GRID K520 GPU.\n",
    "'''\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "from keras.utils import np_utils\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.3\n"
     ]
    }
   ],
   "source": [
    "    import platform\n",
    "     \n",
    "    print(platform.python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow\n",
      "Version: 1.4.0\n",
      "Summary: TensorFlow helps the tensors flow\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: opensource@google.com\n",
      "License: Apache 2.0\n",
      "Location: c:\\anaconda2\\envs\\cnn1\\lib\\site-packages\n",
      "Requires: numpy, six, wheel, enum34, protobuf, tensorflow-tensorboard\n"
     ]
    }
   ],
   "source": [
    "! pip show tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available kernels:\n",
      "  python3    C:\\Anaconda2\\envs\\cnn2\\share\\jupyter\\kernels\\python3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Anaconda2\\\\envs\\\\cnn2\\\\python.exe'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!jupyter kernelspec list\n",
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 0 0 ..., 0 0 0]\n",
      "  [0 0 0 ..., 0 0 0]\n",
      "  [0 0 0 ..., 0 0 0]\n",
      "  ..., \n",
      "  [0 0 0 ..., 0 0 0]\n",
      "  [0 0 0 ..., 0 0 0]\n",
      "  [0 0 0 ..., 0 0 0]]\n",
      "\n",
      " [[0 0 0 ..., 0 0 0]\n",
      "  [0 0 0 ..., 0 0 0]\n",
      "  [0 0 0 ..., 0 0 0]\n",
      "  ..., \n",
      "  [0 0 0 ..., 0 0 0]\n",
      "  [0 0 0 ..., 0 0 0]\n",
      "  [0 0 0 ..., 0 0 0]]\n",
      "\n",
      " [[0 0 0 ..., 0 0 0]\n",
      "  [0 0 0 ..., 0 0 0]\n",
      "  [0 0 0 ..., 0 0 0]\n",
      "  ..., \n",
      "  [0 0 0 ..., 0 0 0]\n",
      "  [0 0 0 ..., 0 0 0]\n",
      "  [0 0 0 ..., 0 0 0]]]\n",
      "(60000, 28, 28)\n",
      "[5 0 4]\n",
      "(60000,)\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  51 159 253\n",
      "  159  50   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  48 238 252 252\n",
      "  252 237   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  54 227 253 252 239\n",
      "  233 252  57   6   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  10  60 224 252 253 252 202\n",
      "   84 252 253 122   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 163 252 252 252 253 252 252\n",
      "   96 189 253 167   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  51 238 253 253 190 114 253 228\n",
      "   47  79 255 168   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  48 238 252 252 179  12  75 121  21\n",
      "    0   0 253 243  50   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  38 165 253 233 208  84   0   0   0   0\n",
      "    0   0 253 252 165   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   7 178 252 240  71  19  28   0   0   0   0\n",
      "    0   0 253 252 195   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  57 252 252  63   0   0   0   0   0   0   0\n",
      "    0   0 253 252 195   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 198 253 190   0   0   0   0   0   0   0   0\n",
      "    0   0 255 253 196   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  76 246 252 112   0   0   0   0   0   0   0   0\n",
      "    0   0 253 252 148   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  85 252 230  25   0   0   0   0   0   0   0   0\n",
      "    7 135 253 186  12   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  85 252 223   0   0   0   0   0   0   0   0   7\n",
      "  131 252 225  71   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  85 252 145   0   0   0   0   0   0   0  48 165\n",
      "  252 173   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  86 253 225   0   0   0   0   0   0 114 238 253\n",
      "  162   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  85 252 249 146  48  29  85 178 225 253 223 167\n",
      "   56   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  85 252 252 252 229 215 252 252 252 196 130   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  28 199 252 252 253 252 252 233 145   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  25 128 252 253 252 141  37   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[:3])\n",
    "print(x_train.shape)\n",
    "print(y_train[:3])\n",
    "print(y_train.shape)\n",
    "print(x_train[1,:,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels_last\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(K.image_data_format())\n",
    "x_train.shape[0],img_rows, img_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K.image_data_format:\n",
    "- https://keras.io/backend/\n",
    "- https://keras.io/preprocessing/image/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.2       ]\n",
      "  [ 0.62352943]\n",
      "  [ 0.99215686]\n",
      "  [ 0.62352943]\n",
      "  [ 0.19607843]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.1882353 ]\n",
      "  [ 0.93333334]\n",
      "  [ 0.98823529]\n",
      "  [ 0.98823529]\n",
      "  [ 0.98823529]\n",
      "  [ 0.92941177]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.21176471]\n",
      "  [ 0.89019608]\n",
      "  [ 0.99215686]\n",
      "  [ 0.98823529]\n",
      "  [ 0.93725491]\n",
      "  [ 0.9137255 ]\n",
      "  [ 0.98823529]\n",
      "  [ 0.22352941]\n",
      "  [ 0.02352941]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.03921569]\n",
      "  [ 0.23529412]\n",
      "  [ 0.87843138]\n",
      "  [ 0.98823529]\n",
      "  [ 0.99215686]\n",
      "  [ 0.98823529]\n",
      "  [ 0.79215688]\n",
      "  [ 0.32941177]\n",
      "  [ 0.98823529]\n",
      "  [ 0.99215686]\n",
      "  [ 0.47843137]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.63921571]\n",
      "  [ 0.98823529]\n",
      "  [ 0.98823529]\n",
      "  [ 0.98823529]\n",
      "  [ 0.99215686]\n",
      "  [ 0.98823529]\n",
      "  [ 0.98823529]\n",
      "  [ 0.3764706 ]\n",
      "  [ 0.74117649]\n",
      "  [ 0.99215686]\n",
      "  [ 0.65490198]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.2       ]\n",
      "  [ 0.93333334]\n",
      "  [ 0.99215686]\n",
      "  [ 0.99215686]\n",
      "  [ 0.74509805]\n",
      "  [ 0.44705883]\n",
      "  [ 0.99215686]\n",
      "  [ 0.89411765]\n",
      "  [ 0.18431373]\n",
      "  [ 0.30980393]\n",
      "  [ 1.        ]\n",
      "  [ 0.65882355]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.1882353 ]\n",
      "  [ 0.93333334]\n",
      "  [ 0.98823529]\n",
      "  [ 0.98823529]\n",
      "  [ 0.7019608 ]\n",
      "  [ 0.04705882]\n",
      "  [ 0.29411766]\n",
      "  [ 0.47450981]\n",
      "  [ 0.08235294]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.99215686]\n",
      "  [ 0.95294118]\n",
      "  [ 0.19607843]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.14901961]\n",
      "  [ 0.64705884]\n",
      "  [ 0.99215686]\n",
      "  [ 0.9137255 ]\n",
      "  [ 0.81568629]\n",
      "  [ 0.32941177]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.99215686]\n",
      "  [ 0.98823529]\n",
      "  [ 0.64705884]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.02745098]\n",
      "  [ 0.69803923]\n",
      "  [ 0.98823529]\n",
      "  [ 0.94117647]\n",
      "  [ 0.27843139]\n",
      "  [ 0.07450981]\n",
      "  [ 0.10980392]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.99215686]\n",
      "  [ 0.98823529]\n",
      "  [ 0.7647059 ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.22352941]\n",
      "  [ 0.98823529]\n",
      "  [ 0.98823529]\n",
      "  [ 0.24705882]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.99215686]\n",
      "  [ 0.98823529]\n",
      "  [ 0.7647059 ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.7764706 ]\n",
      "  [ 0.99215686]\n",
      "  [ 0.74509805]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 1.        ]\n",
      "  [ 0.99215686]\n",
      "  [ 0.76862746]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.29803923]\n",
      "  [ 0.96470588]\n",
      "  [ 0.98823529]\n",
      "  [ 0.43921569]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.99215686]\n",
      "  [ 0.98823529]\n",
      "  [ 0.58039218]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.33333334]\n",
      "  [ 0.98823529]\n",
      "  [ 0.90196079]\n",
      "  [ 0.09803922]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.02745098]\n",
      "  [ 0.52941179]\n",
      "  [ 0.99215686]\n",
      "  [ 0.72941178]\n",
      "  [ 0.04705882]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.33333334]\n",
      "  [ 0.98823529]\n",
      "  [ 0.87450981]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.02745098]\n",
      "  [ 0.51372552]\n",
      "  [ 0.98823529]\n",
      "  [ 0.88235295]\n",
      "  [ 0.27843139]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.33333334]\n",
      "  [ 0.98823529]\n",
      "  [ 0.56862748]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.1882353 ]\n",
      "  [ 0.64705884]\n",
      "  [ 0.98823529]\n",
      "  [ 0.67843139]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.33725491]\n",
      "  [ 0.99215686]\n",
      "  [ 0.88235295]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.44705883]\n",
      "  [ 0.93333334]\n",
      "  [ 0.99215686]\n",
      "  [ 0.63529414]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.33333334]\n",
      "  [ 0.98823529]\n",
      "  [ 0.97647059]\n",
      "  [ 0.57254905]\n",
      "  [ 0.1882353 ]\n",
      "  [ 0.11372549]\n",
      "  [ 0.33333334]\n",
      "  [ 0.69803923]\n",
      "  [ 0.88235295]\n",
      "  [ 0.99215686]\n",
      "  [ 0.87450981]\n",
      "  [ 0.65490198]\n",
      "  [ 0.21960784]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.33333334]\n",
      "  [ 0.98823529]\n",
      "  [ 0.98823529]\n",
      "  [ 0.98823529]\n",
      "  [ 0.89803922]\n",
      "  [ 0.84313726]\n",
      "  [ 0.98823529]\n",
      "  [ 0.98823529]\n",
      "  [ 0.98823529]\n",
      "  [ 0.76862746]\n",
      "  [ 0.50980395]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.10980392]\n",
      "  [ 0.78039217]\n",
      "  [ 0.98823529]\n",
      "  [ 0.98823529]\n",
      "  [ 0.99215686]\n",
      "  [ 0.98823529]\n",
      "  [ 0.98823529]\n",
      "  [ 0.9137255 ]\n",
      "  [ 0.56862748]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.09803922]\n",
      "  [ 0.50196081]\n",
      "  [ 0.98823529]\n",
      "  [ 0.99215686]\n",
      "  [ 0.98823529]\n",
      "  [ 0.5529412 ]\n",
      "  [ 0.14509805]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[1,:,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "        [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "        [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "        [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "        [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]),\n",
       " array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "        [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "        [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.]]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:100],y_test[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout: https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/\n",
    "\n",
    "\n",
    "https://www.quora.com/How-does-the-dropout-method-work-in-deep-learning-And-why-is-it-claimed-to-be-an-effective-trick-to-improve-your-network\n",
    "\n",
    "Dropout is a form of regularisation.\n",
    "\n",
    "**How does it work?**\n",
    "It essentially forces an artificial neural network to learn multiple independent representations of the same data by alternately randomly disabling neurons in the learning phase.\n",
    "\n",
    "**What is the effect of this?**\n",
    "The effect of this is that neurons are prevented from co-adapting too much which makes overfitting less likely.\n",
    "\n",
    "**Why does this happen?**\n",
    "The reason that this works is comparable to why using the mean outputs of many separately trained neural networks to reduces overfitting.\n",
    "\n",
    "**Pooling:** https://cambridgespark.com/content/tutorials/convolutional-neural-networks-with-keras/index.html\n",
    "*This link is also a good source for anther modeling style and padding technique.*\n",
    "\n",
    "**Activation Function:** https://medium.com/the-theory-of-everything/understanding-activation-functions-in-neural-networks-9491262884e0 Baiscally decide whether a neuron should be fired or not. *So, **question:** In the case of convolutional neural net it would mean whther the layer (or the feature) is considered or not?*\n",
    "\n",
    "**Model Structure (general):** Convolutional layers are pooled, more conv layers (and pooling) are applied, followed by flattening. Flat layer is fed in several hidden neural net layers and finally the out put layer with num_classes number of perceptrons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 312s 5ms/step - loss: 0.3276 - acc: 0.8994 - val_loss: 0.0752 - val_acc: 0.9758\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 312s 5ms/step - loss: 0.1134 - acc: 0.9664 - val_loss: 0.0551 - val_acc: 0.9818\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 5121s 85ms/step - loss: 0.0871 - acc: 0.9750 - val_loss: 0.0428 - val_acc: 0.9848\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 311s 5ms/step - loss: 0.0712 - acc: 0.9793 - val_loss: 0.0375 - val_acc: 0.9873\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 334s 6ms/step - loss: 0.0628 - acc: 0.9811 - val_loss: 0.0360 - val_acc: 0.9877\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 350s 6ms/step - loss: 0.0558 - acc: 0.9829 - val_loss: 0.0354 - val_acc: 0.9880\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 352s 6ms/step - loss: 0.0524 - acc: 0.9847 - val_loss: 0.0328 - val_acc: 0.9886\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 336s 6ms/step - loss: 0.0469 - acc: 0.9861 - val_loss: 0.0313 - val_acc: 0.9894\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 330s 5ms/step - loss: 0.0437 - acc: 0.9869 - val_loss: 0.0291 - val_acc: 0.9900\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 332s 6ms/step - loss: 0.0432 - acc: 0.9868 - val_loss: 0.0312 - val_acc: 0.9891\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 323s 5ms/step - loss: 0.0384 - acc: 0.9882 - val_loss: 0.0294 - val_acc: 0.9903\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 325s 5ms/step - loss: 0.0373 - acc: 0.9889 - val_loss: 0.0274 - val_acc: 0.9908\n",
      "Test loss: 0.0274096990818\n",
      "Test accuracy: 0.9908\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count number of params and model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1199882"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good link to understand how num params are caculated and dimensions change: http://cs231n.github.io/convolutional-networks/#conv\n",
    "\n",
    "**On the above link, what do the following mean:**\n",
    "\n",
    "1)*A = cx, derivative with respect to x is c. That means, the gradient has no relationship with X. It is a constant gradient and the descent is going to be on constant gradient. If there is an error in prediction, the changes made by back propagation is constant and not depending on the change in input delta(x) !!!*\n",
    "\n",
    "2) *If you notice, towards either end of the sigmoid function, the Y values tend to respond very less to changes in X. What does that mean? The gradient at that region is going to be small. It gives rise to a problem of vanishing gradients. Hmm. So what happens when the activations reach near the near-horizontal part of the curve on either sides?\n",
    "\n",
    "Gradient is small or has vanished ( cannot make significant change because of the extremely small value ). The network refuses to learn further or is drastically slow ( depending on use case and until gradient /computation gets hit by floating point value limits ). There are ways to work around this problem and sigmoid is still very popular in classification problems.*\n",
    "\n",
    "3) For tanh: *Ok, now this has characteristics similar to sigmoid that we discussed above. It is nonlinear in nature, so great we can stack layers! It is bound to range (-1, 1) so no worries of activations blowing up. One point to mention is that the gradient is stronger for tanh than sigmoid ( derivatives are steeper). Deciding between the sigmoid or tanh will depend on your requirement of gradient strength. Like sigmoid, tanh also has the vanishing gradient problem.*\n",
    "\n",
    "4) *Using a sigmoid or tanh will cause almost all neurons to fire in an analog way ( remember? ).*\n",
    "\n",
    "5) For example, a sigmoid works well for a classifier ( see the graph of sigmoid, doesnt it show the properties of an ideal classifier? ) because approximating a classifier function as combinations of sigmoid is easier than maybe ReLu, for example. Which will lead to faster training process and convergence. \n",
    "\n",
    "\n",
    "**Question: How does max_pooling2d_2 change size from 24x24 to only 12x12. It should reduce it to a size four times smaller right?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
